from tqdm import tqdm
import random
import pandas as pd
import config

random.seed(2022)

# -------------------------------------------------------
#   Preprocessor
# -------------------------------------------------------
class Preprocessor():
    # -------------------------------------------------------
    #   Init
    # -------------------------------------------------------
    def __init__(self, network='', offline_mining_strategy={}):
        self.network = network
        self.offline_mining_strategy = offline_mining_strategy

    # -------------------------------------------------------
    #   Preprocess
    # -------------------------------------------------------
    def preprocess(self):
        print('\n# -------------------------------------------------------')
        print('#    Preprocessing')
        print('# -------------------------------------------------------')
        
        # -------------------------------------------------------
        #   Negative data mining strategy
        # -------------------------------------------------------
        if self.offline_mining_strategy['mine-neg-strategy'] == 'naive': 
            # read naive training set
            pos_df = pd.read_parquet(config.pchome_datasets_folder + '/search/pchome_search_click_dataset/train/naive_trainset/pos_df.parquet')
            neg_df = pd.read_parquet(config.pchome_datasets_folder + '/search/pchome_search_click_dataset/train/naive_trainset/neg_df.parquet')
            
        elif self.offline_mining_strategy['mine-neg-strategy'] == 'basic': pos_df, neg_df = self.mine_negative_basic()
        # elif self.offline_mining_strategy['mine-neg-strategy'] == 'intent-based': pos_df, neg_df = self.mine_negative_intent_based()
        elif self.offline_mining_strategy['mine-neg-strategy'] == 'intent-based':
            # read intent-based training set
            pos_df = pd.read_parquet(config.intent_pos_sm_df_path)
            neg_df = pd.read_parquet(config.intent_neg_sm_df_path)

        elif self.offline_mining_strategy['mine-neg-strategy'] == 'ner-neg': 

            target_store_no_df = pd.read_parquet(config.pchome_datasets_folder + '/search/ner_trainset/ner_trainset_target_store_no.parquet')
            target_rg_no_df = pd.read_parquet(config.pchome_datasets_folder + '/search/ner_trainset/ner_trainset_target_rg_no.parquet')
            target_rg_no_group_df = pd.read_parquet(config.pchome_datasets_folder + '/search/ner_trainset/ner_trainset_target_rg_no_group.parquet')

            ner_trainset = pd.concat([target_rg_no_df, target_rg_no_group_df])
            ner_trainset = ner_trainset.drop_duplicates()
            ner_trainset = ner_trainset.rename({'query': 'anchor'}, axis=1)

            # shuffle
            train_df = ner_trainset.sample(frac=1, random_state=2022).reset_index(drop=True)

            # format data
            data = []
            for a, p, n in tqdm(zip(train_df['anchor'], train_df['pos'], train_df['neg'])):
                data.append([a, p, n])
            return data, None, None                

        elif self.offline_mining_strategy['mine-neg-strategy'] == 'train-lg-clean_intent-based-book-neg-2':
            train_df = pd.read_parquet(config.pchome_datasets_folder + '/search/pchome_search_click_dataset/train/ablation_study/train-lg-clean_intent-based-book-neg-2/train_df.parquet')
            # format data
            data = []
            for a, p, n in tqdm(zip(train_df['anchor'], train_df['pos'], train_df['neg'])):
                data.append([a, p, n])
            return data, None, None

        elif self.offline_mining_strategy['mine-neg-strategy'] == 'train-lg-clean_intent-based-neg-2':
            train_df = pd.read_parquet(config.pchome_datasets_folder + '/search/pchome_search_click_dataset/train/ablation_study/train-lg-clean_intent-based-neg-2/train_df.parquet')
            # format data
            data = []
            for a, p, n in tqdm(zip(train_df['anchor'], train_df['pos'], train_df['neg'])):
                data.append([a, p, n])
            return data, None, None

        elif self.offline_mining_strategy['mine-neg-strategy'] == 'train-sm-clean_intent-based-book-neg-2':
            train_df = pd.read_parquet(config.pchome_datasets_folder + '/search/pchome_search_click_dataset/train/ablation_study/train-sm-clean_intent-based-book-neg-2/train_df.parquet')
            # format data
            data = []
            for a, p, n in tqdm(zip(train_df['anchor'], train_df['pos'], train_df['neg'])):
                data.append([a, p, n])
            return data, None, None

        elif self.offline_mining_strategy['mine-neg-strategy'] == 'train-sm-clean_intent-based-neg-2':
            train_df = pd.read_parquet(config.pchome_datasets_folder + '/search/pchome_search_click_dataset/train/ablation_study/train-sm-clean_intent-based-neg-2/train_df.parquet')
            # format data
            data = []
            for a, p, n in tqdm(zip(train_df['anchor'], train_df['pos'], train_df['neg'])):
                data.append([a, p, n])
            return data, None, None

        # -------------------------------------------------------
        #   Format for siamese network
        # -------------------------------------------------------
        if self.network == 'siamese':
            print('Format siamese training set ...')
            train_df = pd.concat([pos_df, neg_df])
            train_df = train_df.sample(frac=1, random_state=2022).reset_index(drop=True)
            data = []
            labels = []
            for q, n, l in tqdm(zip(train_df['query'], train_df['name'], train_df['label'])):
                data.append([q, n])
                labels.append(l)
            return data, labels

        # -------------------------------------------------------
        #   Format for triplet network
        # -------------------------------------------------------
        elif self.network == 'triplet':
            print('Format triplet training set ...')

            pos_df = pos_df[['query_id', 'query', 'name']]
            pos_df = pos_df.rename({'query': 'anchor', 'name': 'pos'}, axis=1)
            neg_df = neg_df[['query_id', 'query', 'name']]
            neg_df = neg_df.rename({'query': 'anchor','name': 'neg'}, axis=1)
            train_df = pos_df.merge(neg_df, on=['query_id','anchor'], how='inner')
            train_df = train_df[['anchor', 'pos', 'neg']]

            print('number of training data :', len(train_df))

            # shuffle
            train_df = train_df.sample(frac=1, random_state=2022).reset_index(drop=True)

            # format data
            data = []
            for a, p, n in tqdm(zip(train_df['anchor'], train_df['pos'], train_df['neg'])):
                data.append([a, p, n])
            return data, None, None
            
        # -------------------------------------------------------
        #   Format for triplet network (ner-finetune)
        # -------------------------------------------------------
        elif self.network == 'ner-finetune':
            train_df = pd.read_parquet(config.ner_trainset_path)
            # shuffle
            train_df = train_df.sample(frac=1, random_state=2022).reset_index(drop=True)
            # format data
            data = []
            for a, p, n in tqdm(zip(train_df['anchor'], train_df['pos'], train_df['neg'])):
                data.append([a, p, n])
            return data, None
